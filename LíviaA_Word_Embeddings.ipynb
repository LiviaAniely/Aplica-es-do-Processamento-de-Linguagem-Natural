{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LiviaAniely/Aplica-es-do-Processamento-de-Linguagem-Natural/blob/main/L%C3%ADviaA_Word_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Treinando e praticando Word Embeddings\n",
        "\n",
        "Neste colab, serão realizadas as seguintes tarefas:\n",
        "- treinamento de um word embedding em dados jurídicos e avaliação do mesmo em tarefas de similaridade e analogia;\n",
        "- treinamento de um word embedding em dados de comentários de produtos da Amazon e aplicá-los para classificação de sentimentos."
      ],
      "metadata": {
        "id": "6Mo_cFSMrtWv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xLNX2yrHdfV"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "from gensim import utils\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection          import train_test_split\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression, Perceptron\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KI_0Ve2I-g9A"
      },
      "source": [
        "Nesta atividade você irá exercitar o que aprendeu sobre Word Embeddings na disciplina nas seguintes tarefas:\n",
        "- treinamento de um word embedding em dados jurídicos e avaliação do mesmo em tarefas de similaridade e analogia;\n",
        "- treinamento de um word embedding em dados de comentários de produtos da Amazon e aplicá-los para classificação de sentimentos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QesG4ukQ_9jg"
      },
      "source": [
        "# 1. Treinando um word embedding com word2vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poCcy7MbABPH"
      },
      "source": [
        "Nesta tarefa iremos criar nossos próprios word embeddings. Para isso usaremos dados que são documentos jurídicos coletados da plataforma Jusbrasil.\n",
        "\n",
        "Para criar nossos embeddings usaremos a classe `Word2Vec` da biblioteca `gensim`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVMqZJrLAr2x",
        "outputId": "2012fd6f-e341-4f80-a614-eb9601e4b745"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-09-30 01:47:17--  https://raw.githubusercontent.com/issilva5/oclsnippets/master/teor_judiciario.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 39955780 (38M) [text/plain]\n",
            "Saving to: ‘teor_inteiro_jusbrasil.txt’\n",
            "\n",
            "\r          teor_inte   0%[                    ]       0  --.-KB/s               \rteor_inteiro_jusbra 100%[===================>]  38.10M   208MB/s    in 0.2s    \n",
            "\n",
            "2023-09-30 01:47:17 (208 MB/s) - ‘teor_inteiro_jusbrasil.txt’ saved [39955780/39955780]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/issilva5/oclsnippets/master/teor_judiciario.txt -O teor_inteiro_jusbrasil.txt\n",
        "from gensim.models import Word2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mrFoIZiAvxE"
      },
      "source": [
        "Essa classe recebe em sua inicialização alguns parâmetros importantes:\n",
        " - *corpus_file*: o caminho para um arquivo em que cada documento está contido em uma linha.\n",
        " - *vector_size*: o tamanho do vetor de embedding a ser gerado.\n",
        " - *window_size*: o tamanho da janela a ser considerada no modelo ao buscar por palavras vizinhas.\n",
        "\n",
        "\n",
        " Para a atividade você deve explorar **cinco** valores diferentes para pelo menos um desses parâmetros. Isto é, por exemplo, você pode decidir usar vector_size = 50 e testar variar o window_size entre 1 e 5. Ou window_size = 4 e variar o vector_size em [25, 50, 100, 200, 300]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjxe0-NMChw-"
      },
      "outputs": [],
      "source": [
        "# Na forma (vector_size, window_size)\n",
        "\n",
        "combinacoes = [\n",
        "    (50,1),\n",
        "    (50,2),\n",
        "    (50,3),\n",
        "    (50,4),\n",
        "    (50,5),\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQu3Owu-CCUy"
      },
      "source": [
        "**Treinamento dos modelos:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KnlTRuzJA8l_"
      },
      "outputs": [],
      "source": [
        "modelos = [Word2Vec(corpus_file='teor_inteiro_jusbrasil.txt', window = ws, vector_size = vs).wv for vs, ws in combinacoes]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shwHggLKFBW4"
      },
      "source": [
        "## 1.1 Quais as top-5 palavras mais similares a juiz? Como elas variam considerando as diferentes configurações? Você acha que elas fazem sentido?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zxsl9hxIFQLn",
        "outputId": "4c53d97a-f792-49ed-e0e4-fae4b40058f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo 0 - vector_size = 50, window_size = 1\n",
            "[('magistrado', 0.818531334400177),\n",
            " ('juíza', 0.7879314422607422),\n",
            " ('desembargador', 0.7224813103675842),\n",
            " ('juízo', 0.7134191393852234),\n",
            " ('togado', 0.6991901993751526)]\n",
            "--------------------------------------------------------------------------------\n",
            "Modelo 1 - vector_size = 50, window_size = 2\n",
            "[('magistrado', 0.747343897819519),\n",
            " ('juíza', 0.7423506379127502),\n",
            " ('desembargador', 0.7181423306465149),\n",
            " ('julgador', 0.6640152931213379),\n",
            " ('togado', 0.6547998785972595)]\n",
            "--------------------------------------------------------------------------------\n",
            "Modelo 2 - vector_size = 50, window_size = 3\n",
            "[('desembargador', 0.7492721676826477),\n",
            " ('juíza', 0.7401902675628662),\n",
            " ('magistrado', 0.6945540904998779),\n",
            " ('(juiz', 0.6548905372619629),\n",
            " ('juiz,', 0.635075032711029)]\n",
            "--------------------------------------------------------------------------------\n",
            "Modelo 3 - vector_size = 50, window_size = 4\n",
            "[('juíza', 0.7312962412834167),\n",
            " ('desembargador', 0.7238537073135376),\n",
            " ('(juiz', 0.6752033233642578),\n",
            " ('magistrado', 0.6712350249290466),\n",
            " ('juíza,', 0.6564213633537292)]\n",
            "--------------------------------------------------------------------------------\n",
            "Modelo 4 - vector_size = 50, window_size = 5\n",
            "[('juíza', 0.735194742679596),\n",
            " ('(juiz', 0.6980679035186768),\n",
            " ('desembargador', 0.697171688079834),\n",
            " ('magistrado', 0.6548095345497131),\n",
            " ('juíza,', 0.6282491683959961)]\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for i, modelo in enumerate(modelos):\n",
        "  print(f'Modelo {i} - vector_size = {combinacoes[i][0]}, window_size = {combinacoes[i][1]}')\n",
        "\n",
        "  # Cálculo das palavras mais similares\n",
        "  most_similar_words = modelos[i].most_similar('juiz',topn = 5)\n",
        "\n",
        "  pprint(most_similar_words)\n",
        "  print('-'*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKnyogmuF7-t"
      },
      "source": [
        "Nos 5 modelos, as respostas retornadas fazem sentido, apesar de algumas variações, são elas: juíza, desembargador, magistrado, juízo, julgador, juiz, togado.\n",
        "\n",
        "Variando o parâmetro window_size, vemos que as repostas se modificam levemente, de forma a mudar a ordem e o aparecimento de outras palavras, além da própria palavra \"juiz\" em alguns dos modelos, também é possível observar que em alguns modelos houve repetição de palavras.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5708bXQGKZ3"
      },
      "source": [
        "## 1.2 Responda a analogia promotora está para juiz como promotor está para o que? Houve diferença nas respostas considerando os diferentes modelos? Qual deu a melhor resposta?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WccPyDlvGhq5",
        "outputId": "2d196953-f648-454d-88ad-5f315b179b1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo 0 - vector_size = 50, window_size = 1\n",
            "[('magistrado', 0.7723170518875122),\n",
            " ('juízo', 0.6746059656143188),\n",
            " ('juíza', 0.6562816500663757),\n",
            " ('juiz,', 0.6557014584541321),\n",
            " ('togado', 0.6525790095329285),\n",
            " ('desembargador', 0.6475762128829956),\n",
            " ('dies', 0.6264380216598511),\n",
            " ('apenado', 0.6195945739746094),\n",
            " ('julgador', 0.6120823621749878),\n",
            " ('indiciado', 0.5898969769477844)]\n",
            "--------------------------------------------------------------------------------\n",
            "Modelo 1 - vector_size = 50, window_size = 2\n",
            "[('magistrado', 0.7505690455436707),\n",
            " ('juiz,', 0.7488563656806946),\n",
            " ('julgador', 0.6753515005111694),\n",
            " ('juízo', 0.6290488839149475),\n",
            " ('magistrado,', 0.6214197874069214),\n",
            " ('togado', 0.6202765703201294),\n",
            " ('desembargador', 0.6173224449157715),\n",
            " ('incidente,', 0.5965878963470459),\n",
            " ('dies', 0.588655412197113),\n",
            " ('fisco', 0.5499539375305176)]\n",
            "--------------------------------------------------------------------------------\n",
            "Modelo 2 - vector_size = 50, window_size = 3\n",
            "[('desembargador', 0.6699693202972412),\n",
            " ('juiz,', 0.6238680481910706),\n",
            " ('magistrado', 0.6092268228530884),\n",
            " ('julgador', 0.5843796133995056),\n",
            " ('dies', 0.5570328235626221),\n",
            " ('togado', 0.5169697999954224),\n",
            " ('(desembargador', 0.5117136240005493),\n",
            " ('juízo', 0.5110931992530823),\n",
            " ('(juiz', 0.5085254311561584),\n",
            " ('senhor', 0.5061514973640442)]\n",
            "--------------------------------------------------------------------------------\n",
            "Modelo 3 - vector_size = 50, window_size = 4\n",
            "[('desembargador', 0.6586886644363403),\n",
            " ('magistrado', 0.6465192437171936),\n",
            " ('incidente,', 0.6276929974555969),\n",
            " ('juiz,', 0.6127667427062988),\n",
            " ('julgador', 0.6088547110557556),\n",
            " ('juízo', 0.5842834711074829),\n",
            " ('dies', 0.5528542995452881),\n",
            " ('(juiz', 0.5499951839447021),\n",
            " ('ante,', 0.5185121893882751),\n",
            " ('togado', 0.51688551902771)]\n",
            "--------------------------------------------------------------------------------\n",
            "Modelo 4 - vector_size = 50, window_size = 5\n",
            "[('incidente,', 0.6405996084213257),\n",
            " ('desembargador', 0.6248438954353333),\n",
            " ('julgador', 0.5954521894454956),\n",
            " ('magistrado', 0.5787259936332703),\n",
            " ('(juiz', 0.5777144432067871),\n",
            " ('juízo', 0.5693522095680237),\n",
            " ('juiz,', 0.5475215911865234),\n",
            " ('dies', 0.5048975944519043),\n",
            " ('grau,', 0.5019029974937439),\n",
            " ('revisor,', 0.47902345657348633)]\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def analogia(model, x1,x2,y1):\n",
        "  y2 = model.most_similar(positive = [x2, y1], negative = [x1])\n",
        "  return y2\n",
        "\n",
        "for i, modelo in enumerate(modelos):\n",
        "  print(f'Modelo {i} - vector_size = {combinacoes[i][0]}, window_size = {combinacoes[i][1]}')\n",
        "  # O cálculo da analogia\n",
        "  pprint(analogia(modelo, \"promotora\",\"juiz\",\"promotor\"))\n",
        "\n",
        "  print('-'*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOZS46YoGmGF"
      },
      "source": [
        "A resposta esperada mais adequeada para a analogia da questão é \"juíza\".\n",
        "Observando os modelos, os 5 produziram respostas diferentes, a maioria dos modelos não conseguiu prever a palavra certa também.\n",
        "Analisando os modelos, vemos que o que obteve melhor posicionamento sobre a analogia foi o modelo 0, que colocou \"juíza\" na 3° posição.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boAfn9exGtGq"
      },
      "source": [
        "## 1.3 A variação do parâmetro escolhido impactou na qualidade dos modelos gerados? Porquê você acha que esse parâmetro impactou (ou não) a qualidade dos modelos?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIdidkndH1yd"
      },
      "source": [
        "Sim, nota-se que a variação do parâmetro windows_size(window) afetou os resultados, já que é possível observar mudanças nas repostas, seja na verificação das palavras mais similares ou para fazer analogias, e apesar de nesses casos, as respostas no geral não serem tão diferentes, é possível observar alguns problemas em algumas respostas(como repetição de palavras) ou ausência da palavra certa na analogia."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1zbw4bsIXM5"
      },
      "source": [
        "## 1.4 Utilize o modelo que você julgar como o melhor para encontrar um caso de palavra em que as palavras mais similares não fazem muito sentido. Por que você acha que o modelo não foi bem neste caso?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbuxKJV5IihL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "847ce946-eb17-4895-e490-755bc0d9920c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('impende', 0.8965938687324524),\n",
            " ('convém', 0.894428014755249),\n",
            " ('insta', 0.8778426647186279),\n",
            " ('devese', 0.8584142327308655)]\n"
          ]
        }
      ],
      "source": [
        "pprint(modelos[0].most_similar('cumpre',topn = 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsmcD_fNIk06"
      },
      "source": [
        "Apesar do modelo 0 ter sido o melhor nas tarefas propostas acima, é fato que ele não é perfeito. Como no exemplo acima, ao buscar a palavra mais similar a \"cumpre\", a palavra \"impede\" foi a mais similar, definitivamente elas duas não têm um sentido semelhante, o mesmo é válido para as outras palavras retornadas. Como existe um word2vec montado a partir de um texto limitado em quantidade de palavras para analisar, é natural que para certas palavras, não haja um retorno bom. Esse modelo 0 tem o window_size de menor tamanho entre os modelos, esse parâmetro determina quantas palavras de contexto serão usadas para a avaliação, com um número pequeno, é natural que seja levado em consideração apenas as palavras mais próximas, o que para algumas delas, pode promover um resultado não tão bom."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPUHxDawIyYB"
      },
      "source": [
        "# 2. Usando word embeddings para classificação de sentimento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkAjtbt7_pNX"
      },
      "source": [
        "É possível utilizar word embeddings para classificação de sentimentos através de modelos de linguagem, porém nesta atividade exploraremos uma forma mais simples de usar word embeddings para esta tarefa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7xGVNagJLfa"
      },
      "source": [
        "Primeiramente, execute a célula seguinte para gerar o dataset. Os dados que serão utilizados são comentários em produtos no site Amazon."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2YSqQOn_oiq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02213635-e93b-437a-a593-58db809f2aa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-09-30 01:52:24--  https://raw.githubusercontent.com/larifeliciana/books-reviews-portuguese/master/books_pt_neg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 315761 (308K) [text/plain]\n",
            "Saving to: ‘books_pt_neg’\n",
            "\n",
            "books_pt_neg        100%[===================>] 308.36K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2023-09-30 01:52:25 (6.65 MB/s) - ‘books_pt_neg’ saved [315761/315761]\n",
            "\n",
            "--2023-09-30 01:52:25--  https://raw.githubusercontent.com/larifeliciana/books-reviews-portuguese/master/books_pt_pos\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 430160 (420K) [text/plain]\n",
            "Saving to: ‘books_pt_pos’\n",
            "\n",
            "books_pt_pos        100%[===================>] 420.08K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2023-09-30 01:52:25 (8.38 MB/s) - ‘books_pt_pos’ saved [430160/430160]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/larifeliciana/books-reviews-portuguese/master/books_pt_neg -O books_pt_neg\n",
        "!wget https://raw.githubusercontent.com/larifeliciana/books-reviews-portuguese/master/books_pt_pos -O books_pt_pos\n",
        "\n",
        "corpus_neg = []\n",
        "corpus_pos = []\n",
        "\n",
        "for line in open('books_pt_neg'):\n",
        "  corpus_neg.append(utils.simple_preprocess(line))\n",
        "\n",
        "for line in open('books_pt_pos'):\n",
        "  corpus_pos.append(utils.simple_preprocess(line))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9Bb471UJ7Lx"
      },
      "source": [
        "A variável *corpus_neg* contém os comentários negativos, enquanto a variável *corpus_pos* contém os comentários positivos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jf5H4RhVJ507"
      },
      "outputs": [],
      "source": [
        "corpus_neg[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ph3bcqbzJ0o5"
      },
      "outputs": [],
      "source": [
        "corpus_pos[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Re8v0aWQKh0U"
      },
      "source": [
        "Agora para treinar nossos modelos precisamos obter uma representação de cada sentença como um vetor de features, que chamaremos de *sentence embedding*. Nesta atividade iremos gerar os sentence embedding através da média dos word embeddings das palavras que compõem cada sentença."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb9WWNitKw4d"
      },
      "source": [
        "Primeiramente, crie um novo modelo Word2Vec usando ambos os conjuntos de sentenças, com parâmetros a sua escolha."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyWBMEQg-OAn"
      },
      "outputs": [],
      "source": [
        "sentencas = corpus_neg + corpus_pos\n",
        "\n",
        "modelo = Word2Vec(sentencas, window = 5, vector_size = 50, min_count = 1).wv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhcPByloLg08"
      },
      "source": [
        "Agora vamos criar uma função que dada uma sentença e um modelo Word2Vec retorna o *sentence embedding* dessa sentença. Para calcular a média dos vetores você pode utilizar a função `np.mean`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9SvkK_eeLgG3"
      },
      "outputs": [],
      "source": [
        "def get_sentence_embedding(sentence, model):\n",
        "\n",
        "  vec_palavras = []\n",
        "  sentence_embeddings = []\n",
        "\n",
        "  for i in range(len(sentence)):\n",
        "    vec = model[sentence[i]]\n",
        "    vec_palavras.append(vec)\n",
        "\n",
        "  sentence_embeddings = np.mean(vec_palavras,axis=0)\n",
        "\n",
        "  return sentence_embeddings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upvXwvgpMVn3"
      },
      "source": [
        "A seguir você deve aplicar a função sobre os dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gt8egts0MhFI"
      },
      "outputs": [],
      "source": [
        "# Calcule a lista com os embeddings das sentenças negativas\n",
        "sentences_embeddings_neg = []\n",
        "\n",
        "for i in range(len(corpus_neg)):\n",
        "  if(len(corpus_neg[i]) != 0):\n",
        "    x = get_sentence_embedding(corpus_neg[i], modelo)\n",
        "    sentences_embeddings_neg.append(x)\n",
        "\n",
        "# Calcule a lista com os embeddings das sentenças positivas\n",
        "sentences_embeddings_pos = []\n",
        "\n",
        "for i in range(len(corpus_pos)):\n",
        "  if(len(corpus_pos[i]) != 0):\n",
        "    x = get_sentence_embedding(corpus_pos[i], modelo)\n",
        "    sentences_embeddings_pos.append(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVoOy62zNwN8"
      },
      "outputs": [],
      "source": [
        "X = np.concatenate([sentences_embeddings_neg, sentences_embeddings_pos])\n",
        "y = np.concatenate([[-1]*len(sentences_embeddings_neg), [1]*len(sentences_embeddings_pos)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXgf5CeINssB"
      },
      "source": [
        "Crie uma partição treino e teste usando a função `train_test_split` do sklearn, usando as variáveis X e y acima."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0VCccVZOFOm"
      },
      "outputs": [],
      "source": [
        "# Criação da partição treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VELbINQYOINH"
      },
      "source": [
        "## 2.1 Agora instancie pelo menos dois modelos de classificação, em seguida os treine e avalie na sua partição. Discuta os resultados em termos das métricas previamentes vistas em sala."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aW250gAiOZie",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a5ef5f5-20e3-42c5-e147-ba0467d4ee8d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1, -1,  1, -1, -1,  1, -1, -1,  1,  1])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Treinamento e avaliação do modelo de regressão logística\n",
        "\n",
        "clr = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
        "clr.predict(X_test)[:10]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Métricas\n",
        "print(classification_report(y_test, clr.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFaAQjMW2CrT",
        "outputId": "4aa67090-26bf-4b5b-80a7-22cb3c977daa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.60      0.53      0.56       204\n",
            "           1       0.56      0.63      0.60       196\n",
            "\n",
            "    accuracy                           0.58       400\n",
            "   macro avg       0.58      0.58      0.58       400\n",
            "weighted avg       0.58      0.58      0.58       400\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pu9QzOC_OcPi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad60ae2f-a44c-4af1-b4c2-b0241b407a78"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Treinamento e avaliação do modelo de Perceptron\n",
        "\n",
        "p = Perceptron(tol=1e-3, random_state=0).fit(X_train, y_train)\n",
        "p.predict(X_test)[:10]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Métricas\n",
        "print(classification_report(y_test, p.predict(X_test), zero_division = 0.0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbZEeofh2cCe",
        "outputId": "8b3248b8-515c-4bfb-9973-879254693ddc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.51      0.99      0.67       204\n",
            "           1       0.50      0.01      0.02       196\n",
            "\n",
            "    accuracy                           0.51       400\n",
            "   macro avg       0.51      0.50      0.35       400\n",
            "weighted avg       0.51      0.51      0.35       400\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8KfnyzCOecr"
      },
      "source": [
        "O 1° modelo usado foi o de regressão logística. Analisando as métricas, vê-se que o obteve uma acurácia de 58%.\n",
        "\n",
        "o 2° modelo usado foi o Perceptron. Ao analisar suas métricas, vê-se uma acurácia de 51%.\n",
        "\n",
        "O 1° modelo se saiu melhor na classificação, porém ambos modelos, no geral, com esses valores de acurácia não podem ser considerados bons de fato para esses dados."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}